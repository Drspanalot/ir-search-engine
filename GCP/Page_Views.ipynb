{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Page Views\n",
    "\n",
    "**Important: DO NOT CLEAR THE OUTPUT OF THIS NOTEBOOK AFTER EXECUTION!!!**\n",
    "\n",
    "This notebook downloads Wikipedia page view statistics and creates a dictionary mapping doc_id -> page_views.\n",
    "\n",
    "**Output:** `gs://db204905756/page_views/pageview.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-cloud-storage==1.43.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud dataproc clusters list --region us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "\n",
    "# Bucket configuration\n",
    "bucket_name = 'db204905756'\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(bucket_name)\n",
    "\n",
    "print(f\"✅ Connected to bucket: {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if Page Views Already Exist\n",
    "\n",
    "No need to download again if we already have it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if pageview.pkl already exists\n",
    "existing = !gsutil ls gs://$bucket_name/page_views/pageview.pkl 2>/dev/null\n",
    "\n",
    "if existing and 'pageview.pkl' in str(existing):\n",
    "    print(\"✅ pageview.pkl already exists! You can skip the download.\")\n",
    "    print(\"   Location: gs://\" + bucket_name + \"/page_views/pageview.pkl\")\n",
    "    SKIP_DOWNLOAD = True\n",
    "else:\n",
    "    print(\"Page views not found. Will download and process.\")\n",
    "    SKIP_DOWNLOAD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Page View Data\n",
    "\n",
    "**Skip this section if pageview.pkl already exists!**\n",
    "\n",
    "Downloads ~2.3GB file from Wikimedia and processes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if we need to download\n",
    "if not SKIP_DOWNLOAD:\n",
    "    pv_path = 'https://dumps.wikimedia.org/other/pageview_complete/monthly/2021/2021-08/pageviews-202108-user.bz2'\n",
    "    p = Path(pv_path) \n",
    "    pv_name = p.name\n",
    "    pv_temp = f'{p.stem}-4dedup.txt'\n",
    "    \n",
    "    print(\"Downloading page views file (~2.3GB)...\")\n",
    "    print(\"This will take about 10-15 minutes...\")\n",
    "    !wget -N $pv_path\n",
    "    print(\"\\n✅ Download complete!\")\n",
    "else:\n",
    "    print(\"Skipping download - file already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if we need to process\n",
    "if not SKIP_DOWNLOAD:\n",
    "    pv_path = 'https://dumps.wikimedia.org/other/pageview_complete/monthly/2021/2021-08/pageviews-202108-user.bz2'\n",
    "    p = Path(pv_path) \n",
    "    pv_name = p.name\n",
    "    pv_temp = f'{p.stem}-4dedup.txt'\n",
    "    \n",
    "    print(\"Extracting and filtering English Wikipedia pages...\")\n",
    "    print(\"This will take a few minutes...\")\n",
    "    \n",
    "    # Filter for English pages, keep article ID (field 3) and page views (field 5)\n",
    "    # Use grep -E instead of grep -P for compatibility\n",
    "    !bzcat $pv_name | grep \"^en\\.wikipedia\" | cut -d' ' -f3,5 | grep -E \"^[0-9]+\\s[0-9]+$\" > $pv_temp\n",
    "    \n",
    "    print(\"✅ Extraction complete!\")\n",
    "    \n",
    "    # Check file size\n",
    "    !ls -lh $pv_temp\n",
    "else:\n",
    "    print(\"Skipping extraction - file already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if we need to process\n",
    "if not SKIP_DOWNLOAD:\n",
    "    pv_temp = 'pageviews-202108-user-4dedup.txt'\n",
    "    \n",
    "    print(\"Creating page view dictionary...\")\n",
    "    \n",
    "    # Create a Counter that sums up page views for the same article\n",
    "    wid2pv = Counter()\n",
    "    \n",
    "    with open(pv_temp, 'rt') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            parts = line.strip().split(' ')\n",
    "            if len(parts) == 2:\n",
    "                try:\n",
    "                    wid2pv.update({int(parts[0]): int(parts[1])})\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            # Progress indicator\n",
    "            if i % 1000000 == 0 and i > 0:\n",
    "                print(f\"  Processed {i:,} lines...\")\n",
    "    \n",
    "    print(f\"\\n✅ Created dictionary with {len(wid2pv):,} articles\")\n",
    "    \n",
    "    # Convert to defaultdict\n",
    "    page_view_dict = defaultdict(int)\n",
    "    for doc_id, views in wid2pv.items():\n",
    "        page_view_dict[doc_id] = views\n",
    "    \n",
    "    # Show some stats\n",
    "    top_10 = wid2pv.most_common(10)\n",
    "    print(f\"\\nTop 10 most viewed articles:\")\n",
    "    for doc_id, views in top_10:\n",
    "        print(f\"  Doc ID {doc_id}: {views:,} views\")\n",
    "else:\n",
    "    print(\"Skipping processing - file already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if we need to save\n",
    "if not SKIP_DOWNLOAD:\n",
    "    print(\"Saving page view dictionary...\")\n",
    "    \n",
    "    # Save locally\n",
    "    with open(\"pageview.pkl\", 'wb') as f:\n",
    "        pickle.dump(dict(page_view_dict), f)\n",
    "    \n",
    "    # Upload to GCS - to page_views folder (won't overwrite anything!)\n",
    "    blob = bucket.blob('page_views/pageview.pkl')\n",
    "    blob.upload_from_filename('pageview.pkl')\n",
    "    \n",
    "    print(f\"\\n✅ Saved to gs://{bucket_name}/page_views/pageview.pkl\")\n",
    "else:\n",
    "    print(\"File already exists in GCS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Files in page_views/:\")\n",
    "!gsutil ls -lh gs://$bucket_name/page_views/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the file\n",
    "print(\"Testing load from GCS...\")\n",
    "\n",
    "blob = bucket.blob('page_views/pageview.pkl')\n",
    "contents = blob.download_as_bytes()\n",
    "loaded_pv = pickle.loads(contents)\n",
    "\n",
    "print(f\"✅ Successfully loaded {len(loaded_pv):,} page view entries\")\n",
    "\n",
    "# Show sample\n",
    "sample_ids = list(loaded_pv.keys())[:5]\n",
    "print(f\"\\nSample entries:\")\n",
    "for doc_id in sample_ids:\n",
    "    print(f\"  Doc ID {doc_id}: {loaded_pv[doc_id]:,} views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up (Optional)\n",
    "\n",
    "Remove the large temporary files to free up disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up temporary files\n",
    "# !rm -f pageviews-202108-user.bz2\n",
    "# !rm -f pageviews-202108-user-4dedup.txt\n",
    "# !rm -f pageview.pkl\n",
    "# print(\"✅ Temporary files removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### File Created:\n",
    "\n",
    "| File | Location | Description |\n",
    "|------|----------|-------------|\n",
    "| pageview.pkl | page_views/ | Dictionary mapping doc_id -> page views |\n",
    "\n",
    "### Usage in search_frontend.py:\n",
    "\n",
    "```python\n",
    "# Load page views\n",
    "from google.cloud import storage\n",
    "import pickle\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket('db204905756')\n",
    "blob = bucket.blob('page_views/pageview.pkl')\n",
    "page_views = pickle.loads(blob.download_as_bytes())\n",
    "\n",
    "# Get page views for a document\n",
    "doc_id = 12345\n",
    "views = page_views.get(doc_id, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✅ Page Views - COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nLocation: gs://{bucket_name}/page_views/pageview.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
